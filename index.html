<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Salifort Motors: Keeping Our People Happy</title>
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="css/style.css">
    <link rel="stylesheet" href="https://unpkg.com/aos@2.3.1/dist/aos.css">
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet" />
</head>
<body>

    <header class="header fade-in">
        <h1>Salifort Motors: Keeping Our People Happy</h1>
        <p><i>Using Data to Understand Employee Retention</i></p>
    </header>

    <nav class="navbar">
        <a href="#story" class="active">The Story</a>
        <a href="#clues">Finding Clues</a>
        <a href="#predictions">Making Predictions</a>
        <a href="#solutions">Solutions</a>
        <a href="#code">Code Showcase</a>
        <a href="#about">About</a>
    </nav>

    <main>
        <section id="story" class="container section" data-aos="fade-up" aria-labelledby="story-heading">
            <h2 id="story-heading">The Story: Why Employee Happiness Matters More Than Ever</h2>
            <p>Hi, I'm <b>Tobin Zolkowski</b>. Welcome! Ever wonder what makes a workplace truly great? It's the people. At Salifort Motors, we value our team immensely. But recently, we noticed a concerning trend: more talented folks were leaving than we were comfortable with. Losing great employees isn't just about replacement costs; it impacts morale, slows innovation, and means losing valuable experience.</p>
            <p>So, we became data detectives! We gathered anonymous information about employee experiences – satisfaction levels, workload, tenure, growth opportunities, and more. Our mission: uncover hidden patterns and understand the real story behind <i>why</i> some thrive and stay, while others move on.</p>
            <p>Think of it as listening to thousands of voices at once, finding common threads. Our goal is to use these insights not just to reduce turnover, but to proactively build a more supportive, engaging, and happier workplace for everyone at Salifort Motors. When our people succeed, the company succeeds.</p>
        </section>

        <section id="clues" class="container section" data-aos="fade-up" aria-labelledby="clues-heading">
            <h2 id="clues-heading">Finding Clues: Listening to the Data's Whispers</h2>
            <p>Our investigation examined the experiences of <span class="highlight">15,000 employees</span>, looking at ten key factors:</p>
            <ul>
                <li><b>Happiness Level (Satisfaction)</b>: How content were people? (A crucial clue!)</li>
                <li><b>Performance Score (Last Evaluation)</b>: How did their recent performance review go?</li>
                <li><b>Project Load (Number of Projects)</b>: Were they juggling a few key tasks or swimming in projects?</li>
                <li><b>Work Hours (Average Monthly Hours)</b>: Were they working standard hours, or consistently burning the midnight oil?</li>
                <li><b>Time with Company (Tenure)</b>: How many years had they dedicated to Salifort?</li>
                <li><b>Workplace Safety (Work Accident)</b>: Had they unfortunately experienced an accident on the job?</li>
                <li><b>Left Company?</b>: The big question – did they stay or did they go?</li>
                <li><b>Recent Promotion? (Last 5 Years)</b>: Had they moved up the ladder recently?</li>
                <li><b>Team (Department)</b>: Which part of the Salifort family did they belong to?</li>
                <li><b>Pay Level (Salary)</b>: How did their compensation compare – low, medium, or high?</li>
            </ul>
            <button class="collapsible" aria-expanded="false" aria-controls="data-prep-content">Getting the Data Ready (A Quick Peek Behind the Scenes)</button>
            <div class="content" id="data-prep-content">
                <p>Before finding insights, we performed digital housekeeping: cleaning data, ensuring consistency, and translating categories (like 'Department') for our analysis tools. It's like organizing detective notes before connecting the dots!</p>
            </div>

            <h4>Visual Clues: What the Charts Revealed</h4>
            <p>Numbers can be dry, but charts bring the story to life! We created visualizations to spot trends. Here's what jumped out:</p>

            <figure class="image-container tooltip">
                <img src="images/image_1.png" alt="Boxplot showing employee tenure distribution. Median tenure is 3 years, with many leaving between years 2 and 4." loading="lazy">
                <figcaption class="caption">Chart 1: The Salifort Journey - How Long Do People Stay?</figcaption>
                <span class="tooltiptext">Most employees stay around 3 years. The 2-4 year mark is key.</span>
            </figure>
            <p>This chart shows the typical employee journey length. The median tenure is <span class="highlight">around 3 years</span>. Many people move on between their second and fourth year, signaling this timeframe is critical for ensuring employees feel valued and see a future here.</p>

            <figure class="image-container tooltip">
                <img src="images/image_2.png" alt="Correlation heatmap showing relationships between employee factors. Strong negative correlation between satisfaction level and leaving." loading="lazy">
                <figcaption class="caption">Chart 2: Connecting the Dots - What Factors are Linked?</figcaption>
                <span class="tooltiptext">Shows links between different factors. Unhappiness is strongly linked to leaving.</span>
            </figure>
            <p>This "heatmap" is like a relationship map. Darker colors mean stronger connections. The most striking? <span class="highlight">Unhappiness (low satisfaction) has a strong link to employees leaving</span>. The data confirms it clearly. We also saw links suggesting top performers might be feeling strained (more projects linked to higher reviews and longer hours).</p>

            <figure class="image-container tooltip">
                <img src="images/image_3.png" alt="Bar chart showing number of employees who left by department. Sales, Technical, and Support departments have the highest counts." loading="lazy">
                <figcaption class="caption">Chart 3: Where Are People Leaving From? (Team View)</figcaption>
                <span class="tooltiptext">Sales, Technical, and Support teams saw the most departures.</span>
            </figure>
            <p>When we looked at departures by department, the <span class="highlight">Sales, Technical, and Support teams stood out</span>. Now, these are large teams, so more departures are expected. However, it does suggest we should perhaps look closer at the unique pressures or opportunities within these specific groups.</p>

            <figure class="image-container tooltip">
                <img src="images/image_4.png" alt="Bar chart comparing employees who left vs. stayed across salary levels. Significantly more low-salary employees left compared to medium or high." loading="lazy">
                <figcaption class="caption">Chart 4: Does Pay Make a Difference?</figcaption>
                <span class="tooltiptext">Yes! Lower pay is linked to higher chances of leaving.</span>
            </figure>
            <p>Money talks. This chart clearly shows: <span class="highlight">employees in the lower salary bracket were significantly more likely to leave</span> compared to colleagues earning medium or high salaries. Compensation is a major factor.</p>

            <figure class="image-container tooltip">
                <img src="images/image_12.png" alt="Bar chart showing the distribution of employees across low, medium, and high salary levels. Most employees are in the low and medium bands." loading="lazy">
                <figcaption class="caption">Chart 5: The Salary Landscape at Salifort</figcaption>
                <span class="tooltiptext">Most employees are in the low or medium pay bands.</span>
            </figure>
            <p>This chart adds important context to the previous one. It shows that <span class="highlight">a large portion of Salifort's workforce falls into the low and medium salary categories</span>. This distribution helps explain *why* pay appears to be such a significant driver of turnover – it affects a large number of our people.</p>

            <figure class="image-container tooltip">
                <img src="images/image_5.png" alt="Histogram of employee satisfaction levels. Shows a bimodal distribution with peaks at low satisfaction (around 0.1 and 0.4) and high satisfaction (around 0.7-1.0)." loading="lazy">
                <figcaption class="caption">Chart 6: The Mood Map - How Happy Are Our Teams?</figcaption>
                <span class="tooltiptext">Shows two main groups: very unhappy and quite happy. Few in the middle.</span>
            </figure>
            <p>Employee happiness isn't a simple bell curve. We see <span class="highlight">two distinct groups: a significant cluster of very unhappy employees, and another large group who are quite satisfied</span>. Few people feel just "okay." This polarization suggests we need tailored strategies.</p>

            <figure class="image-container tooltip">
                <img src="images/image_6.png" alt="Histogram of last evaluation scores. Shows a bimodal distribution with peaks around 0.5-0.6 and near 1.0." loading="lazy">
                <figcaption class="caption">Chart 7: Performance Snapshot - How Are Reviews Looking?</figcaption>
                <span class="tooltiptext">Scores often cluster around average and high marks.</span>
            </figure>
            <p>Performance reviews also showed interesting clusters. Many employees received scores <span class="highlight">around the middle range, while another group scored very highly</span>. How people perceive their performance and the feedback process could be intertwined with their overall satisfaction and workload.</p>

            <figure class="image-container tooltip">
                <img src="images/image_7.png" alt="Histogram showing the number of projects employees work on. Most common numbers are 3 and 4 projects." loading="lazy">
                <figcaption class="caption">Chart 8: Juggling Act - How Many Projects Per Person?</figcaption>
                <span class="tooltiptext">Most people handle 3-4 projects. Some handle many more (up to 7!).</span>
            </figure>
            <p>What's a typical workload like? Most employees are juggling <span class="highlight">3 or 4 projects simultaneously</span>. However, some are focused on fewer, while others are tackling a demanding 6 or 7! Finding the sweet spot is crucial. Too few projects might lead to boredom, but too many is a recipe for burnout.</p>

            <figure class="image-container tooltip">
                <img src="images/image_8.png" alt="Histogram of average monthly hours worked. Shows two main groups: one around 150 hours/month, another around 220-270 hours/month." loading="lazy">
                <figcaption class="caption">Chart 9: Punching the Clock - What Do Work Hours Look Like?</figcaption>
                <span class="tooltiptext">Shows two groups: one working standard hours, another working very long hours.</span>
            </figure>
            <p>Work hours show two distinct patterns: one group working fairly standard hours (around <span class="highlight">150 per month</span>), and another consistently putting in significantly more time (<span class="highlight">220-270 hours per month</span>). These long hours could be a major red flag for burnout.</p>

            <figure class="image-container tooltip">
                <img src="images/image_9.png" alt="Histogram showing employee tenure in years. The highest bar is at 3 years, with counts decreasing significantly after 5 years." loading="lazy">
                <figcaption class="caption">Chart 10: Years of Service - The 3-Year Milestone</figcaption>
                <span class="tooltiptext">Confirms the 3-year mark is key, with fewer staying past 5 years.</span>
            </figure>
            <p>This chart reinforces our earlier finding about the employee journey. The <span class="highlight">most common tenure is 3 years</span>. After the 5-year mark, the numbers drop off noticeably. This highlights a potential challenge in retaining experienced employees long-term.</p>

            <figure class="image-container tooltip">
                <img src="images/image_10.png" alt="Stacked bar chart comparing promotion status (yes/no in last 5 years) for employees who left vs. stayed. Very few promoted employees left." loading="lazy">
                <figcaption class="caption">Chart 11: The Power of Promotion!</figcaption>
                <span class="tooltiptext">Employees who get promoted rarely leave. Growth matters!</span>
            </figure>
            <p>This clue is powerful: <span class="highlight">employees promoted within the last 5 years almost never left</span>. This clearly demonstrates how vital growth opportunities and feeling valued through advancement are for retention.</p>

            <figure class="image-container tooltip">
                <img src="images/image_11.png" alt="Stacked bar chart comparing work accident status (yes/no) for employees who left vs. stayed. A higher proportion of those who stayed had an accident." loading="lazy">
                <figcaption class="caption">Chart 12: An Unexpected Finding - Accidents & Staying</figcaption>
                <span class="tooltiptext">Surprisingly, those with accidents were less likely to leave.</span>
            </figure>
            <p>Here's a curveball from the data: employees who experienced a work accident were actually <span class="highlight">less likely to leave</span>. Safety is paramount, always. But this unexpected finding suggests that perhaps the support systems that kick in after an incident, or other factors, play a role in these employees choosing to stay.</p>
        </section>

        <section id="predictions" class="container section" data-aos="fade-up" aria-labelledby="predictions-heading">
            <h2 id="predictions-heading">Making Predictions: Building an Early Warning System</h2>
            <p>Spotting past clues is insightful, but what about anticipating the future? We built a predictive tool – an early warning system – to identify employees who might be unhappy or considering leaving, allowing proactive support.</p>
            <h3>Testing Our Crystal Balls: Which Predictor Works Best?</h3>
            <p>We tested three different methods to see which could most accurately flag potential departures:</p>
            <h4>Method 1: Simple Logic (Logistic Regression) - The Straightforward Approach</h4>
            <ul>
                <li>Accuracy (Overall Correctness): <span class="highlight">~78%</span> - Okay, but not great.</li>
                <li>Precision (Correctly ID'ing Leavers): <span class="highlight">~73%</span> - When it said someone might leave, it was right about 3 out of 4 times.</li>
                <li>Recall (Finding Most Leavers): <span class="highlight">~69%</span> - Missed identifying nearly a third of those who actually left.</li>
                <li>F1-Score (Balanced Score): <span class="highlight">~71%</span> - A decent balance, but room for improvement.</li>
            </ul>
            <p><i>Result: A reasonable starting point, but not sensitive enough. It let too many potential leavers slip through the cracks unnoticed.</i></p>
            <h4>Method 2: Teamwork Trees (Random Forest) - The Collaborative Approach</h4>
            <ul>
                <li>Accuracy: <span class="highlight">97.83%</span> - Highly accurate overall!</li>
                <li>Precision: <span class="highlight">98%</span> - Very reliable when flagging someone as a potential leaver.</li>
                <li>Recall: <span class="highlight">89%</span> - Successfully identified almost 9 out of 10 employees who left.</li>
                <li>F1-Score: <span class="highlight">93%</span> - Excellent balance between precision and recall.</li>
            </ul>
            <p><i>Result: A huge improvement! This method, which uses many decision trees working together, was much better at accurately identifying employees at risk.</i></p>
            <h4>Method 3: Smart Boosting (XGBoost) - The Expert Learner Approach</h4>
            <ul>
                <li>Accuracy: <span class="highlight">97.96%</span> - The top performer in overall accuracy!</li>
                <li>Precision: <span class="highlight">98%</span> - Just as reliable as Random Forest.</li>
                <li>Recall: <span class="highlight">90%</span> - Slightly better at catching potential leavers (identified 9 out of 10).</li>
                <li>F1-Score: <span class="highlight">94%</span> - The best balance achieved.</li>
            </ul>
            <p><i>Result: Our champion! This advanced method learned exceptionally well, proving slightly more effective at identifying employees who might need support.</i></p>

            <figure class="image-container tooltip">
                <img src="images/image_15.png" alt="ROC curves comparing Logistic Regression, Random Forest, and XGBoost models. Random Forest and XGBoost curves are very close to the top-left corner (AUC 0.98), indicating excellent performance, while Logistic Regression is lower." loading="lazy">
                <figcaption class="caption">Chart 13: Grading the Crystal Balls (ROC Curve)</figcaption>
                <span class="tooltiptext">Higher lines mean better predictions. Methods 2 & 3 (Green/Orange) hug the top-left = Excellent!</span>
            </figure>
            <p>This chart visually confirms the scores. The closer a line gets to the top-left corner, the better the predictor. See how the green (Random Forest) and orange (XGBoost) lines soar high? They achieved an Area Under the Curve (AUC) score of <span class="highlight">0.98</span> (where 1.0 is perfect), vastly outperforming the blue line (Logistic Regression) and the dotted line (pure chance). This gives us great confidence in our advanced methods.</p>

            <h3>What Clues Did the Best Predictors Focus On?</h3>
            <button class="collapsible" aria-expanded="false" aria-controls="feature-importance-content">Which Clues Mattered Most to the Predictors?</button>
            <div class="content" id="feature-importance-content">
                <p>Knowing which clues our best predictors relied on helps focus our efforts. Both models highlighted similar key factors:</p>
                <ul>
                    <li><b>Satisfaction Level:</b> The strongest predictor in the Random Forest model and second in XGBoost. Clearly critical. If someone's unhappy, the models paid attention.</li>
                    <li><b>Tenure (Time with Company):</b> A top-3 factor in both models, emphasizing the importance of the 3-5 year period. How long someone has been here is a key indicator.</li>
                    <li><b>Number of Projects:</b> Ranked #1 by XGBoost and #3 by Random Forest, indicating workload is a major factor. Feeling overloaded (or underutilized) matters.</li>
                    <li><b>Average Monthly Hours:</b> Important for both models, linking long hours to turnover risk. Consistent overtime was a red flag for the predictors.</li>
                    <li><b>Evaluation Score:</b> Also appeared in the top factors, suggesting performance perception and feedback play a role.</li>
                </ul>
                <p><i>Note: The consistency across models confirms that focusing on satisfaction, tenure, workload (projects/hours), and evaluation/growth is key. The predictors learned what our earlier charts suggested!</i></p>
            </div>
            <figure class="image-container tooltip">
                <img src="images/image_13.png" alt="Bar chart showing top 10 feature importances for the Random Forest model. Satisfaction level, tenure, number of projects, evaluation score, and average monthly hours are the top 5." loading="lazy">
                <figcaption class="caption">Chart 14: Top Clues for Teamwork Trees (Random Forest)</figcaption>
                <span class="tooltiptext">Happiness level was the #1 clue for this method.</span>
            </figure>
            <p>Chart 14 breaks down what the "Teamwork Trees" method valued most. It overwhelmingly pointed to <span class="highlight">satisfaction level</span> as the number one predictor, followed by <span class="highlight">tenure (time with company)</span>, <span class="highlight">number of projects</span>, and <span class="highlight">average monthly hours</span>.</p>

            <figure class="image-container tooltip">
                <img src="images/image_14.png" alt="Bar chart showing top 10 feature importances for the XGBoost model. Number of projects, satisfaction level, tenure, average monthly hours, and evaluation score are the top 5." loading="lazy">
                <figcaption class="caption">Chart 15: Top Clues for the Expert Learner (XGBoost)</figcaption>
                <span class="tooltiptext">Project count, satisfaction, and tenure were top clues here.</span>
            </figure>
            <p>Chart 15 shows the perspective of our champion predictor, "Smart Boosting." Interestingly, it ranked <span class="highlight">number of projects</span> as the most critical factor, followed very closely by <span class="highlight">satisfaction level</span> and <span class="highlight">tenure (time with company)</span>. Workload seemed slightly more significant to this model.</p>

            <h3>Our Champion Predictor: XGBoost Takes the Lead</h3>
            <p>While the simple logic method provided a baseline, the advanced "Teamwork Trees" and "Smart Boosting" methods were superior. Because "Smart Boosting" (<span class="highlight">XGBoost</span>) showed slightly better accuracy and, crucially, better recall (identifying employees who might leave), we selected it as our go-to early warning system.</p>
        </section>

        <section id="solutions" class="container section" data-aos="fade-up" aria-labelledby="solutions-heading">
            <h2 id="solutions-heading">Solutions: Turning Insights into Action for a Happier Workplace</h2>
            <p>We've listened to the data, found clues, and built an early warning system. Now, the crucial part: what do we *do*? How can Salifort use these insights to build a workplace where people feel valued, supported, and choose to stay?</p>
            <p><strong>What We Learned (Key Takeaways):</strong></p>
            <ul>
                <li><b>Happiness is Paramount:</b> Low satisfaction isn't just a feeling; it's the biggest predictor of someone leaving.</li>
                <li><b>The Critical Mid-Career Point:</b> The 3-5 year mark is a make-or-break period for many employees.</li>
                <li><b>Workload Balance is Key:</b> Burnout from too many projects/hours, or boredom from too few, pushes people away.</li>
                <li><b>Long Hours Signal Risk:</b> Consistently high monthly hours are a strong indicator of potential departure.</li>
                <li><b>Performance, Recognition & Growth Matter:</b> Feeling stuck, unappreciated, or unfairly evaluated impacts retention.</li>
                <li><b>Promotions are Powerful Retention Tools:</b> Lack of clear advancement opportunities is a major reason people look elsewhere.</li>
                <li><b>Fair Compensation is Foundational:</b> Especially for those in lower salary bands, feeling underpaid is a strong push factor.</li>
            </ul>
            <p><u>Actionable Recommendations for Salifort Motors:</u></p>
            <ol>
                <li><b>Proactively Monitor & Address Satisfaction:</b> Don't wait for exit interviews. Implement regular, light-touch check-ins (like pulse surveys) focused on satisfaction, workload, and recognition. Crucially, act on the feedback promptly.</li>
                <li><b>Optimize Workload Distribution:</b> Managers should actively monitor project counts and average hours. Aim for a challenging but sustainable balance. Use the predictive model to flag potential overload/underload situations early.</li>
                <li><b>Invest in Mid-Career Development & Retention:</b> Pay special attention to employees approaching the 3-5 year mark. Offer targeted development programs, mentorship opportunities, and clear discussions about career paths within Salifort.</li>
                <li><b>Enhance the Performance Review Experience:</b> Ensure reviews are perceived as fair, constructive, and genuinely linked to growth. Train managers to deliver effective feedback and discuss career aspirations.</li>
                <li><b>Strengthen Recognition & Reward Systems:</b> Celebrate successes publicly and privately. Make promotion criteria transparent and achievable. Conduct regular salary benchmarking to ensure competitiveness, paying close attention to the lower and medium bands.</li>
            </ol>
            <p><u>Looking Ahead: Continuous Improvement</u></p>
            <ul>
                <li><b>Gather Qualitative Insights:</b> Supplement the data with real conversations. Conduct "stay interviews" with happy employees and empathetic exit interviews to understand the nuances the numbers can't capture.</li>
                <li><b>Pilot Targeted Interventions:</b> Use the predictive model to identify at-risk groups and pilot specific support programs (e.g., workload adjustments, mentoring, training) for them. Measure the impact.</li>
                <li><b>Keep the Model Fresh:</b> Regularly retrain the predictive model with new employee data to ensure it remains accurate and relevant as the company evolves.</li>
            </ul>
            <p>By taking these steps, Salifort Motors can shift from reacting to turnover to proactively building an environment where talented people choose to build their careers.</p>
        </section>

        <section id="code" class="container section" data-aos="fade-up" aria-labelledby="code-heading">
            <h2 id="code-heading">Code Showcase: Behind the Analysis</h2>
            <p>Here are some key code snippets that powered this analysis. These examples demonstrate the data science workflow from exploration to model building and evaluation.</p>
            
            <h3>Data Exploration & Preprocessing</h3>
            <div class="code-container">
                <div class="code-header">
                    <span class="code-lang">Python</span>
                    <button class="copy-btn" aria-label="Copy code">Copy</button>
                </div>
                <pre><code class="language-python"># Initial data exploration and cleaning
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Load the dataset
df = pd.read_csv('HR_capstone_dataset.csv')

# Quick overview of the dataset
print(f"Dataset shape: {df.shape}")
print(f"Missing values:\n{df.isnull().sum()}")
print(f"Data types:\n{df.dtypes}")

# Check for duplicates
print(f"Duplicate rows: {df.duplicated().sum()}")

# Statistical summary
df.describe()</code></pre>
            </div>

            <h3>Feature Engineering & Correlation Analysis</h3>
            <div class="code-container">
                <div class="code-header">
                    <span class="code-lang">Python</span>
                    <button class="copy-btn" aria-label="Copy code">Copy</button>
                </div>
                <pre><code class="language-python"># Create correlation matrix for key numerical features
numerical_features = ['satisfaction_level', 'last_evaluation', 
                      'number_project', 'average_montly_hours', 
                      'time_spend_company', 'left']

# Calculate correlation matrix
correlation_matrix = df[numerical_features].corr()

# Create heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='RdYlBu_r', 
            center=0, square=True, fmt='.2f')
plt.title('Correlation Heatmap of Employee Features')
plt.tight_layout()
plt.show()

# Identify strong correlations with turnover
turnover_correlations = correlation_matrix['left'].sort_values(ascending=False)
print("Correlations with employee turnover:")
print(turnover_correlations)</code></pre>
            </div>

            <h3>Advanced Model Building - XGBoost</h3>
            <div class="code-container">
                <div class="code-header">
                    <span class="code-lang">Python</span>
                    <button class="copy-btn" aria-label="Copy code">Copy</button>
                </div>
                <pre><code class="language-python"># XGBoost model implementation
from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score

# Prepare features and target
X = df_encoded.drop('left', axis=1)
y = df_encoded['left']

# Split the data
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.25, random_state=42, stratify=y
)

# Define XGBoost model with optimized parameters
xgb_model = XGBClassifier(
    objective='binary:logistic',
    max_depth=6,
    learning_rate=0.1,
    n_estimators=300,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42,
    eval_metric='logloss'
)

# Train the model
xgb_model.fit(X_train, y_train)

# Make predictions
y_pred_xgb = xgb_model.predict(X_test)
y_pred_proba_xgb = xgb_model.predict_proba(X_test)[:, 1]

# Evaluate performance
print("XGBoost Model Performance:")
print(f"Accuracy: {accuracy_score(y_test, y_pred_xgb):.4f}")
print(f"ROC-AUC: {roc_auc_score(y_test, y_pred_proba_xgb):.4f}")
print("\nClassification Report:")
print(classification_report(y_test, y_pred_xgb))</code></pre>
            </div>

            <h3>Feature Importance Visualization</h3>
            <div class="code-container">
                <div class="code-header">
                    <span class="code-lang">Python</span>
                    <button class="copy-btn" aria-label="Copy code">Copy</button>
                </div>
                <pre><code class="language-python"># Feature importance analysis
import matplotlib.pyplot as plt

# Get feature importance from XGBoost model
feature_importance = xgb_model.feature_importances_
feature_names = X_train.columns

# Create DataFrame for easier plotting
importance_df = pd.DataFrame({
    'feature': feature_names,
    'importance': feature_importance
}).sort_values('importance', ascending=False)

# Plot top 10 most important features
plt.figure(figsize=(10, 8))
top_features = importance_df.head(10)
sns.barplot(data=top_features, x='importance', y='feature', palette='viridis')
plt.title('Top 10 Feature Importances - XGBoost Model')
plt.xlabel('Importance Score')
plt.ylabel('Features')
plt.tight_layout()
plt.show()

# Print numerical importance values
print("Top 10 Most Important Features:")
for idx, row in top_features.iterrows():
    print(f"{row['feature']}: {row['importance']:.4f}")</code></pre>
            </div>

            <button class="collapsible" aria-expanded="false" aria-controls="advanced-code-content">Advanced Analytics: ROC Curves & Model Comparison</button>
            <div class="content" id="advanced-code-content">
                <div class="code-container">
                    <div class="code-header">
                        <span class="code-lang">Python</span>
                        <button class="copy-btn" aria-label="Copy code">Copy</button>
                    </div>
                    <pre><code class="language-python"># Model comparison with ROC curves
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt

# Train multiple models for comparison
models = {
    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),
    'Random Forest': RandomForestClassifier(n_estimators=300, random_state=42),
    'XGBoost': XGBClassifier(random_state=42, eval_metric='logloss')
}

# Plot ROC curves
plt.figure(figsize=(10, 8))
colors = ['blue', 'green', 'orange']

for i, (name, model) in enumerate(models.items()):
    # Fit model and predict probabilities
    model.fit(X_train, y_train)
    y_proba = model.predict_proba(X_test)[:, 1]
    
    # Calculate ROC curve
    fpr, tpr, _ = roc_curve(y_test, y_proba)
    roc_auc = auc(fpr, tpr)
    
    # Plot ROC curve
    plt.plot(fpr, tpr, color=colors[i], lw=2, 
             label=f'{name} (AUC = {roc_auc:.3f})')

# Plot diagonal line
plt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--', alpha=0.8)

# Customize plot
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curves - Model Comparison')
plt.legend(loc="lower right")
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()</code></pre>
                </div>
            </div>

            <h3>Business Insights Generation</h3>
            <div class="code-container">
                <div class="code-header">
                    <span class="code-lang">Python</span>
                    <button class="copy-btn" aria-label="Copy code">Copy</button>
                </div>
                <pre><code class="language-python"># Generate actionable business insights
def analyze_high_risk_employees(df, model, feature_names):
    """
    Identify high-risk employees and key characteristics
    """
    # Predict probabilities for all employees
    X_all = df[feature_names]
    risk_scores = model.predict_proba(X_all)[:, 1]
    
    # Add risk scores to dataframe
    df_analysis = df.copy()
    df_analysis['churn_risk'] = risk_scores
    
    # Identify high-risk employees (top 20% risk scores)
    high_risk_threshold = np.percentile(risk_scores, 80)
    high_risk_employees = df_analysis[df_analysis['churn_risk'] >= high_risk_threshold]
    
    print(f"High-risk employees identified: {len(high_risk_employees)}")
    print(f"Average risk score: {high_risk_employees['churn_risk'].mean():.3f}")
    
    # Analyze characteristics of high-risk group
    print("\nHigh-Risk Employee Characteristics:")
    print(f"Average satisfaction: {high_risk_employees['satisfaction_level'].mean():.3f}")
    print(f"Average monthly hours: {high_risk_employees['average_montly_hours'].mean():.1f}")
    print(f"Average tenure: {high_risk_employees['time_spend_company'].mean():.1f} years")
    
    return high_risk_employees

# Apply the analysis
high_risk_group = analyze_high_risk_employees(df_encoded, xgb_model, X.columns)</code></pre>
            </div>

            <p><strong>Technical Stack:</strong> Python, Pandas, NumPy, Scikit-learn, XGBoost, Matplotlib, Seaborn</p>
            <p><em>Want to see the complete analysis? Check out the full <a href="https://github.com/tzolkowski96/tzolkowski96/tree/main/Employee-Churn-Prediction" target="_blank" rel="noopener noreferrer">Jupyter notebook on GitHub</a> with detailed explanations and additional visualizations.</em></p>
        </section>

        <section id="about" class="container section" data-aos="fade-up" aria-labelledby="about-heading">
            <h2 id="about-heading">About This Project & The Data Detective</h2>
            <p>This project translated data into a human story and actionable strategies for Salifort Motors' HR and leadership. It shows how data analysis, combined with business thinking, can lead to meaningful workplace improvements.</p>
            <p>I'm Tobin Zolkowski, the data detective behind this analysis. I'm passionate about using data to uncover insights and solve real-world problems. For the technical details (Python code, model specifics), explore the full analysis on GitHub: <a href="https://github.com/tzolkowski96/tzolkowski96/tree/main/Employee-Churn-Prediction" target="_blank" rel="noopener noreferrer">Salifort Employee Churn Analysis</a>.</p>
            <p><i>Transparency Note: This analysis was part of the Google Advanced Data Analytics Capstone. The dataset, while realistic, was provided for educational purposes.</i></p>
        </section>
    </main>

    <footer class="footer">
        &copy; 2025 Tobin Zolkowski. Data Detective Work. <a href="https://github.com/tzolkowski96/Salifort-Motors-Project" target="_blank" rel="noopener noreferrer">Project on GitHub</a>
    </footer>

    <div class="fullscreen-overlay" id="fullscreen-overlay" role="dialog" aria-modal="true" aria-labelledby="fullscreen-caption" aria-describedby="fullscreen-img" hidden>
        <img id="fullscreen-img" src="" alt="Full screen view of selected chart">
        <div id="fullscreen-caption" class="fullscreen-caption"></div>
        <div class="zoom-container">
            <button class="zoom-in" id="zoom-in" aria-label="Zoom In">Zoom In</button>
            <button class="zoom-out" id="zoom-out" aria-label="Zoom Out">Zoom Out</button>
        </div>
        <button id="close-fullscreen-btn" aria-label="Close full screen image view" style="position:absolute; top:10px; right:10px; background:none; border:none; font-size:24px; cursor:pointer;">×</button>
    </div>

    <script src="js/script.js" defer></script>
    <script src="https://unpkg.com/aos@2.3.1/dist/aos.js"></script>
    <!-- Prism.js for syntax highlighting -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
    <script>
      document.addEventListener('DOMContentLoaded', () => {
        AOS.init({
          duration: 800, // Animation duration
          once: true, // Only animate once
          offset: 100 // Trigger animation slightly before element is in view
         });
      });
    </script>

</body>
</html>
